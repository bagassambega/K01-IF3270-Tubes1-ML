{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Scalar(value=2, grad=720)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "\n",
    "a = Scalar(2)\n",
    "b = Scalar(3)\n",
    "c = a * b\n",
    "d = c * Scalar(4)\n",
    "e = c * Scalar(5)\n",
    "f = d * e\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [4, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 2], [2, 1]])\n",
    "y = np.array([2, 1]).reshape(-1, 1)\n",
    "\n",
    "np.dot(x, y)\n",
    "\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loss: Scalar(value=0.24009999999999998, grad=0)\n",
      "[[Scalar(value=0, grad=0), Scalar(value=0, grad=0)], [Scalar(value=0.01225, grad=0.01225), Scalar(value=0.0245, grad=0.0245)]]\n",
      "[[Scalar(value=0, grad=0), Scalar(value=0, grad=0)], [Scalar(value=0, grad=0), Scalar(value=0, grad=0)], [Scalar(value=0, grad=0), Scalar(value=0, grad=0)], [Scalar(value=0, grad=0), Scalar(value=0, grad=0)]]\n",
      "[[Scalar(value=0, grad=0), Scalar(value=0, grad=0), Scalar(value=0, grad=0), Scalar(value=0, grad=0)]]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "from NeuralNetwork.Visualize import draw_dot\n",
    "import numpy as np\n",
    "from NeuralNetwork.WeightGenerator import normal_distribution\n",
    "from NeuralNetwork.FFNN import FFNN\n",
    "\n",
    "\n",
    "x = np.array([[0.05, 0.1]])\n",
    "y = np.array([0.01])\n",
    "\n",
    "ff = FFNN(x, y, [2, 4], \"sigmoid\", \"zero\", \"mse\", learning_rate=0.5, epochs=1)\n",
    "\n",
    "ff.forward()\n",
    "ff.backprop()\n",
    "# ff.loss_values[0].grad = 1\n",
    "# ff.loss_values[0].backward()\n",
    "\n",
    "for i in range(len(ff.weights)):\n",
    "    print(ff.weights[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'mnist_784' from local file...\n",
      "Dataset (70000, 784), (70000,) loaded.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import os\n",
    "import joblib  # For saving and loading the dataset\n",
    "\n",
    "def get_dataset(name: str = 'mnist_784'):\n",
    "    \"\"\"Get dataset from OpenML, checking local data folder first.\n",
    "\n",
    "    Args:\n",
    "        name (str): Name of the dataset on OpenML.\n",
    "    \"\"\"\n",
    "    cwd: str = os.getcwd()\n",
    "    data_dir = os.path.join(cwd, 'data')\n",
    "    dataset_path = os.path.join(data_dir, f\"{name}.joblib\")  # Path to save/load dataset\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"Loading dataset '{name}' from local file...\")\n",
    "        X, y = joblib.load(dataset_path)\n",
    "        return X, y\n",
    "    else:\n",
    "        print(f\"Fetching dataset '{name}' from OpenML...\")\n",
    "        try:\n",
    "            dataset = fetch_openml(name, version=1, return_X_y=True, data_home=data_dir)\n",
    "            X, y = dataset\n",
    "            joblib.dump((X, y), dataset_path)  # Save the dataset\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise f\"Error fetching or saving dataset: {e}\"\n",
    "\n",
    "X, y = get_dataset()\n",
    "if X is not None:\n",
    "    print(f\"Dataset {X.shape}, {y.shape} loaded.\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(70000, 784)\n",
      "(30, 784)\n",
      "(30, 1)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "from NeuralNetwork.Visualize import draw_dot\n",
    "import numpy as np\n",
    "from NeuralNetwork.WeightGenerator import normal_distribution\n",
    "from NeuralNetwork.FFNN import FFNN\n",
    "\n",
    "y = np.array([[float(y[i])] for i in range(len(y))])\n",
    "print(X.shape)\n",
    "\n",
    "temp_x = X[0:30]\n",
    "temp_y = y[0:30]\n",
    "\n",
    "print(temp_x.shape)\n",
    "print(temp_y.shape)\n",
    "\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss: Scalar(value=[Scalar(value=25.0, grad=0)], grad=0)\n",
      "1\n",
      "Loss: Scalar(value=[Scalar(value=0.0, grad=0)], grad=0)\n",
      "2\n",
      "Loss: Scalar(value=[Scalar(value=16.0, grad=0)], grad=0)\n",
      "3\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "4\n",
      "Loss: Scalar(value=[Scalar(value=81.0, grad=0)], grad=0)\n",
      "5\n",
      "Loss: Scalar(value=[Scalar(value=4.0, grad=0)], grad=0)\n",
      "6\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "7\n",
      "Loss: Scalar(value=[Scalar(value=9.0, grad=0)], grad=0)\n",
      "8\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "9\n",
      "Loss: Scalar(value=[Scalar(value=16.0, grad=0)], grad=0)\n",
      "10\n",
      "Loss: Scalar(value=[Scalar(value=9.0, grad=0)], grad=0)\n",
      "11\n",
      "Loss: Scalar(value=[Scalar(value=25.0, grad=0)], grad=0)\n",
      "12\n",
      "Loss: Scalar(value=[Scalar(value=9.0, grad=0)], grad=0)\n",
      "13\n",
      "Loss: Scalar(value=[Scalar(value=36.0, grad=0)], grad=0)\n",
      "14\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "15\n",
      "Loss: Scalar(value=[Scalar(value=49.0, grad=0)], grad=0)\n",
      "16\n",
      "Loss: Scalar(value=[Scalar(value=4.0, grad=0)], grad=0)\n",
      "17\n",
      "Loss: Scalar(value=[Scalar(value=64.0, grad=0)], grad=0)\n",
      "18\n",
      "Loss: Scalar(value=[Scalar(value=36.0, grad=0)], grad=0)\n",
      "19\n",
      "Loss: Scalar(value=[Scalar(value=81.0, grad=0)], grad=0)\n",
      "20\n",
      "Loss: Scalar(value=[Scalar(value=16.0, grad=0)], grad=0)\n",
      "21\n",
      "Loss: Scalar(value=[Scalar(value=0.0, grad=0)], grad=0)\n",
      "22\n",
      "Loss: Scalar(value=[Scalar(value=81.0, grad=0)], grad=0)\n",
      "23\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "24\n",
      "Loss: Scalar(value=[Scalar(value=1.0, grad=0)], grad=0)\n",
      "25\n",
      "Loss: Scalar(value=[Scalar(value=4.0, grad=0)], grad=0)\n",
      "26\n",
      "Loss: Scalar(value=[Scalar(value=16.0, grad=0)], grad=0)\n",
      "27\n",
      "Loss: Scalar(value=[Scalar(value=9.0, grad=0)], grad=0)\n",
      "28\n",
      "Loss: Scalar(value=[Scalar(value=4.0, grad=0)], grad=0)\n",
      "29\n",
      "Loss: Scalar(value=[Scalar(value=49.0, grad=0)], grad=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ffnn = FFNN(x=temp_x, y=temp_y, layers=[2, 3], weight_method=\"zero\")\n",
    "\n",
    "ffnn.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
