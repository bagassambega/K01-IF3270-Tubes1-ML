{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "\n",
    "a = Scalar(2)\n",
    "b = Scalar(3)\n",
    "c = a * b\n",
    "d = c * Scalar(4)\n",
    "e = c * Scalar(5)\n",
    "f = d * e\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Layer 0 [[Scalar(w00=0.0, grad=0), Scalar(w01=0.0, grad=0)], [Scalar(w10=0.0, grad=0), Scalar(w11=0.0, grad=0)]]\n",
      "Layer 1 [[Scalar(w00=-0.06125, grad=0), Scalar(w01=-0.06125, grad=0)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from NeuralNetwork.FFNN import FFNN\n",
    "\n",
    "x = np.array([[0.05, 0.1]])\n",
    "y = np.array([0.01])\n",
    "\n",
    "ff = FFNN(x, y, [2], \"sigmoid\", \"zero\", \"mse\", batch_size=1, epochs=1, learning_rate=0.5)\n",
    "\n",
    "ff.fit()\n",
    "\n",
    "for i, weight in enumerate(ff.weights):\n",
    "    print(\"Layer\", i, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 2], [2, 1]])\n",
    "y = np.array([2, 1]).reshape(-1, 1)\n",
    "\n",
    "np.dot(x, y)\n",
    "\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "from NeuralNetwork.Visualize import draw_dot\n",
    "import numpy as np\n",
    "from NeuralNetwork.WeightGenerator import normal_distribution\n",
    "from NeuralNetwork.FFNN import FFNN\n",
    "\n",
    "\n",
    "x = np.array([[0.05, 0.1]])\n",
    "y = np.array([0.01])\n",
    "\n",
    "ff = FFNN(x, y, [2, 4], \"sigmoid\", \"zero\", \"mse\", learning_rate=0.5, epochs=1)\n",
    "\n",
    "ff.forward()\n",
    "ff.backprop()\n",
    "# ff.loss_values[0].grad = 1\n",
    "# ff.loss_values[0].backward()\n",
    "\n",
    "for i in range(len(ff.weights)):\n",
    "    print(ff.weights[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import os\n",
    "import joblib  # For saving and loading the dataset\n",
    "\n",
    "def get_dataset(name: str = 'mnist_784'):\n",
    "    \"\"\"Get dataset from OpenML, checking local data folder first.\n",
    "\n",
    "    Args:\n",
    "        name (str): Name of the dataset on OpenML.\n",
    "    \"\"\"\n",
    "    cwd: str = os.getcwd()\n",
    "    data_dir = os.path.join(cwd, 'data')\n",
    "    dataset_path = os.path.join(data_dir, f\"{name}.joblib\")  # Path to save/load dataset\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"Loading dataset '{name}' from local file...\")\n",
    "        X, y = joblib.load(dataset_path)\n",
    "        return X, y\n",
    "    else:\n",
    "        print(f\"Fetching dataset '{name}' from OpenML...\")\n",
    "        try:\n",
    "            dataset = fetch_openml(name, version=1, return_X_y=True, data_home=data_dir)\n",
    "            X, y = dataset\n",
    "            joblib.dump((X, y), dataset_path)  # Save the dataset\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            raise f\"Error fetching or saving dataset: {e}\"\n",
    "\n",
    "X, y = get_dataset()\n",
    "if X is not None:\n",
    "    print(f\"Dataset {X.shape}, {y.shape} loaded.\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NeuralNetwork.Autograd import Scalar\n",
    "from NeuralNetwork.Visualize import draw_dot\n",
    "import numpy as np\n",
    "from NeuralNetwork.WeightGenerator import normal_distribution\n",
    "from NeuralNetwork.FFNN import FFNN\n",
    "\n",
    "y = np.array([float(y[i]) for i in range(len(y))])\n",
    "print(X.shape)\n",
    "\n",
    "temp_x = X[0:30]\n",
    "temp_y = y[0:30]\n",
    "\n",
    "print(temp_x.shape)\n",
    "print(temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = FFNN(x=temp_x, y=temp_y, layers=[2, 3], weight_method=\"zero\", batch_size=5, verbose=True)\n",
    "\n",
    "ffnn.forward()\n",
    "ffnn.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
