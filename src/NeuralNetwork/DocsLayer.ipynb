{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Layer as ffp\n",
    "import importlib\n",
    "importlib.reload(ffp)\n",
    "\n",
    "from Layer import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh penggunaan kode\n",
    "pada kode di bawah ini adalah cara pemanggilan untuk Layer dan melakukan forward propagation\n",
    "\n",
    "inputs: np.array 2Dimensi \n",
    "\n",
    "untuk memanggil Layer baru kita bisa memanggil Dense \n",
    "Dense: \n",
    "    neurons: jumlah neuron yang ada pada layer tersebut\n",
    "    activation: activation function yang akan digunakan untuk output dari layer tersebut \n",
    "    inputShape: inputya dalam dimensi berapa dalam contoh dibawah digunakan (3,) yang berarti matriks 3 x 1 (row x col)\n",
    "\n",
    "Untuk melakukan feed forward propagation kita bisa memanggil fungsi method call\n",
    "```python\n",
    "outputs = dense_layer.call(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer hidden 1 output: [[0.09222589 1.04375267 0.         1.09028192]]\n",
      "Layer output: [[0.39535104 0.39945488]]\n"
     ]
    }
   ],
   "source": [
    "# Use a tuple (3,) for inputShape instead of (3)\n",
    "inputs = np.array([[0.5, 0.2, -0.1]])\n",
    "\n",
    "# Create a Dense layer with 4 neurons, 'relu' activation, and input shape (3,)\n",
    "dense_layer = Dense(neurons=4, activation='relu', inputShape=(3,))\n",
    "outputs = dense_layer.call(inputs)\n",
    "print(\"Layer hidden 1 output:\", outputs)\n",
    "\n",
    "# Create a Dense layer with 2 neurons, 'sigmoid' activation, and input shape (4,)\n",
    "dense_layer2 = Dense(neurons=2, activation='sigmoid', inputShape=(4,))\n",
    "outputs2 = dense_layer2.call(outputs)\n",
    "print(\"Layer output:\", outputs2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contoh penggunaan untuk inisialisi bobot sesuai spesifikasi \n",
    "\n",
    "contoh 1: bobot default \n",
    "\n",
    "contoh 2: untuk pemanggilan menggunakan uniform method \n",
    "\n",
    "contoh 3: untuk pemanggilan menggunkan uniform normal \n",
    "\n",
    "contoh 4: untuk zero inisialisasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer hidden 1 output (default/Xavier): [[0.         0.         0.37496817 1.78596728]]\n",
      "Layer hidden 1 output (uniform): [[0.08576399 0.         0.         0.        ]]\n",
      "Layer hidden 1 output (normal): [[0.07582605 0.         0.21647917 0.33928599]]\n",
      "Layer hidden 1 output (zero): [[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Contoh Penggunaan ---\n",
    "\n",
    "# Contoh 1: Inisialisasi dengan metode default (misalnya Xavier uniform)\n",
    "inputs = np.array([[0.5, 0.2, -0.1]])\n",
    "dense_layer = Dense(neurons=4, activation='relu', inputShape=(3,))\n",
    "outputs = dense_layer.call(inputs)\n",
    "print(\"Layer hidden 1 output (default/Xavier):\", outputs)\n",
    "\n",
    "# Contoh 2: Inisialisasi dengan metode uniform dengan parameter khusus\n",
    "weightInitParams = {'lower_bound': -0.1, 'upper_bound': 0.1, 'seed': 42}\n",
    "dense_layer_uniform = Dense(neurons=4, activation='relu', inputShape=(3,),\n",
    "                            weightInit='uniform', weightInitParams=weightInitParams)\n",
    "outputs_uniform = dense_layer_uniform.call(inputs)\n",
    "print(\"Layer hidden 1 output (uniform):\", outputs_uniform)\n",
    "\n",
    "# Contoh 3: Inisialisasi dengan metode normal dengan parameter khusus\n",
    "weightInit_params_normal = {'mean': 0, 'variance': 0.01, 'seed': 42}\n",
    "dense_layer_normal = Dense(neurons=4, activation='relu', inputShape=(3,),\n",
    "                           weightInit='normal', weightInitParams=weightInit_params_normal)\n",
    "outputs_normal = dense_layer_normal.call(inputs)\n",
    "print(\"Layer hidden 1 output (normal):\", outputs_normal)\n",
    "\n",
    "# Contoh 4: Inisialisasi dengan zero initialization\n",
    "dense_layer_zero = Dense(neurons=4, activation='relu', inputShape=(3,),\n",
    "                         weightInit='zero')\n",
    "outputs_zero = dense_layer_zero.call(inputs)\n",
    "print(\"Layer hidden 1 output (zero):\", outputs_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contoh print untuk tiap layer\n",
    "\n",
    "Gunakan kode dibawah untuk merepresentasikan bias dan bobot pada layar\n",
    "```python\n",
    "print(dense_layer.__repr__())\n",
    "```\n",
    "\n",
    "\n",
    "atau untuk print satu-satu bisa digunakan untuk print per attributenya\n",
    "```python\n",
    "print(dense_layer.activation.__name__) # print dense_layer activation\n",
    "print(dense_layer.bias) # print bias\n",
    "print(dense_layer.weight) # print bobot\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer hidden 1 output: [[1.13381352 0.         0.         0.        ]]\n",
      "Layer: \n",
      "activation = relu\n",
      "weights \n",
      " = [[ 0.79878452  0.00210634  0.5903757  -0.89266563]\n",
      " [-0.33676281 -0.74219259  0.74577008  0.39102448]\n",
      " [-0.12676945  0.46412611  0.70561458 -0.35386656]]\n",
      "bias = [ 0.39454844 -0.09550584 -0.78628399 -0.31700335]\n",
      "\n",
      "Layer output: [[0.19354983 0.06454578]]\n",
      "Layer: \n",
      "activation = sigmoid\n",
      "weights \n",
      " = [[-0.14118527 -0.71615106]\n",
      " [-0.92813844 -0.234482  ]\n",
      " [-0.85974723  0.41389049]\n",
      " [ 0.33048532  0.95613027]]\n",
      "bias = [-0.63351466 -0.93083783]\n",
      "\n",
      "name: relu\n",
      "bias: [ 0.39454844 -0.09550584 -0.78628399 -0.31700335]\n",
      "weight: [[ 0.79878452  0.00210634  0.5903757  -0.89266563]\n",
      " [-0.33676281 -0.74219259  0.74577008  0.39102448]\n",
      " [-0.12676945  0.46412611  0.70561458 -0.35386656]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[0.5, 0.2, -0.1]])\n",
    "\n",
    "dense_layer = Dense(neurons=4, activation='relu', inputShape=(3,))\n",
    "outputs = dense_layer.call(inputs)\n",
    "print(\"Layer hidden 1 output:\", outputs)\n",
    "print(dense_layer.__repr__())\n",
    "\n",
    "dense_layer2 = Dense(neurons=2, activation='sigmoid', inputShape=(4,))\n",
    "outputs2 = dense_layer2.call(outputs)\n",
    "print(\"Layer output:\", outputs2)\n",
    "print(dense_layer2.__repr__())\n",
    "\n",
    "# --- Contoh Penggunaan per Attribute---\n",
    "\n",
    "print(f\"name: {dense_layer.activation.__name__}\") # Get activation\n",
    "print(f\"bias: {dense_layer.bias}\") # Get biases\n",
    "print(f\"weight: {dense_layer.weights}\") # Get weights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
